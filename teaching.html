<!DOCTYPE html>
<html lang="en">

<head>
   <meta charset="utf-8">
   <title>Research</title>
   <meta name="viewport" content="width=device-width, initial-scale=1.0">
   <meta name="description" content="Research Lab, Home, Velit Aliquet Sagittis University">
   <meta name="author" content="">
   <!-- Le styles -->
   <link href="css/bootstrap.min.css" rel="stylesheet">
   <link href="css/bootstrap-responsive.min.css" rel="stylesheet">
   <link href="css/theme.css" rel="stylesheet">
   <script src="js/jquery-1.9.1.min.js"></script>
   <script>
      $(function () {
         $("#header").load("header.html");
         $("#footer").load("footer.html");
      });
   </script>
</head>

<body>
   <div class="container">
      <div id="header"></div>
      <div class="masthead">
         <div class="navbar">
            <div class="navbar-inner">
               <div class="container">
                  <ul class="nav">
                     <li><a href="index.html">Home</a></li>
                     <li><a href="people.html">People</a></li>
                     <li><a href="research.html">Research</a></li>
                     <li><a href="publications.html">Publications</a></li>
                     <li><a href="gallery.html">Gallery</a></li>
                     <li><a href="news.html">News</a></li>
                     <li class="active"><a href="#">Teaching</a></li>
                     <li><a href="contact.html">Contact</a></li>
                  </ul>
               </div>
            </div>
         </div>
      </div>
      <hr>
      <div class="row-fluid">
         <div class="span3 bs-docs-sidebar" id="navparent">
            <ul class="nav nav-list bs-docs-sidenav" data-spy="affix" data-offset-top="200" data-offset-bottom="260">
               <li><a href="#CSE417"> CSE417: Data mining and Data warehouse</a></li>
               <li><a href="#CSE417">CSE424: Neural Network</a></li>
            </ul>
         </div>


         <div class="span8 offset1">


            <section id="CSE417">
               <div class="page-header">
                  <h3><a href="">CSE417: Data mining and Data warehouse</a></h3>
                  <hr>
                  <b>Course Description</b>
                  <p>We will learn theory, concepts, and applications on how to extract useful information from huge amounts of data.</p>
                  <p><b>Course Information:</b> <a href="https://docs.google.com/document/d/14s3vStvPZ-_fYjfPdnzL2dL6OPxdOWhE/">Syllabus</a></p>
                  <table class="table table-striped">
                     <thead>
                        <tr>
                           <th>Week</th>
                           <th>Session</th>
                           <th>Topics</th>
                           <th>Resources</th>
                           <th>Assignments</th>
                     </thead>
                     <tbody>

                        <tr>
                           <td>Week-1</td>
                           <td>Session-1</td>
                           <td>Data Matrix, Attributes, Vector Recap, Basic Statistics, Distributions, PDF, CDF</td>
                           <td><a href="">https://dataminingbook.info/resources/</a><br>Book: DMML, Chapter 1 and Chapter 2</td>
                           <td>Assignment-1</td>
                        </tr>

                        <tr>
                           <td>Week-2</td>
                           <td>Session-2</td>
                           <td>Multivariate Gaussian, Covariance Matrix, Geometry of the multivariate normal, Diagonalization of Covariance Matrix</td>
                           <td><a href="">https://dataminingbook.info/resources/</a><br>Book: DMML, Chapter 1 and Chapter 2</td>
                           <td></td>
                        </tr>

                        <tr>
                           <td>Week-3</td>
                           <td>Session-3</td>
                           <td>Frequent Itemset Mining, The Market-Basket Model, Mining Association Rules, Finding Frequent Pairs, A-Priori Algorithm, FP Growth, *Eclat algorithm</td>
                           <td><a href="">http://www.mmds.org/#book</a><br>Book: MMDS, Chapter 6</td>
                           <td>Assignment-2</td>
                        </tr>

                        <tr>
                           <td>Week-4</td>
                           <td>Session-4</td>
                           <td>Mining Data Streams, General Stream Processing Model, Sampling from a Data Stream, *Queries over a (long) Sliding Window</td>
                           <td><a href="">http://www.mmds.org/#book</a><br>Book: MMDS, Chapter 4</td>
                           <td></td>
                        </tr>

                        <tr>
                           <td>Week-5</td>
                           <td>Session-5</td>
                           <td>Analysis of Large Graphs: Link Analysis,  PageRank,  Topic Specific Page rank, *Sim Rank</td>
                           <td><a href="">http://www.mmds.org/#book</a><br>Book: MMDS, Chapter 5</td>
                           <td>Assignment-3</td>
                        </tr>

                        <tr>
                           <td>Week-6</td>
                           <td>Session-6</td>
                           <td>Recommender Systems, Content-based Systems, Collaborative Filtering</td>
                           <td><a href="">http://www.mmds.org/#book/</a<br>>Book: MMDS, Chapter 9</td>
                           <td></td>
                        </tr>

                        <tr>
                           <td>Week-7</td>
                           <td>Session-7</td>
                           <td>Recommender Systems, Latent Factor Models, SVD</td>
                           <td><a href="">http://www.mmds.org/#book</a><br>Book: MMDS, Chapter 9, 11</td>
                           <td>Assignment-4</td>
                        </tr>

                        <tr>
                           <td>Week-8</td>
                           <td>Session-8</td>
                           <td>Application of SVD in recommender system, *SVD for dimension reduction</td>
                           <td><a href="">http://www.mmds.org/#book</a><br>Book: MMDS, Chapter 9, 11</td>
                           <td></td>
                        </tr>

                        <tr>
                           <td>Week-9</td>
                           <td>Session-9</td>
                           <td>Analysis of Large Graphs: Community Detection, Betweenness, Modularity, Graph Partitioning, *Graph Cut, Spectral Partitioning</td>
                           <td><a href="">http://www.mmds.org/#book</a><br>Book: MMDS, Chapter 10</td>
                           <td>Assignment-5</td>
                        </tr>

                        <tr>
                           <td>Week-10</td>
                           <td>Session-10</td>
                           <td>Map-Reduce and the New Software Stack</td>
                           <td><a href="">http://www.mmds.org/#book</a><br>Book: MMDS, Chapter 10</td>
                           <td>Assignment-6</td>
                        </tr>

                        <tr>
                           <td>Week-11</td>
                           <td>Session-11</td>
                           <td>*Finding Similar Items: Locality Sensitive Hashing, *Distance Measure, *MinHashing</td>
                           <td><a href="">http://www.mmds.org/#book</a><br>Book: MMDS, Chapter 3</td>
                           <td></td>
                        </tr>

                        <tr>
                           <td>Week-12</td>
                           <td>Session-12</td>
                           <td></td>
                           <td>TBA</td>
                           <td>TBA</td>
                        </tr>

                     </tbody>
                  </table>
               </div>
            </section>   



            <section id="CSE424">
               <div class="page-header">
                  <h3><a href="">CSE424: Neural Network</a></h3>
                  <hr>
                  <p><b>Course Information:</b> <a href="https://docs.google.com/document/d/10CnG2tGrDCEFF9Vr0qP7tKCoVXF78KeF/edit">Syllabus</a></p>
                  <table class="table table-striped">
                     <thead>
                        <tr>
                           <th>Weeks</th>
                           <th>Topics</th>
                           <th>Lectures</th>
                           <th>Presentation Topics</th>
                     </thead>
                     <tbody>

                        <tr>
                           <td>Week-1</td>
                           <td>Neural Network Basics, Multilayer Perceptron, Linear Classifiers, Loss calculation, Log likelihood loss, Cross Entropy Loss, Softmax Classifier,  Different Activation Functions and their Derivatives</td>
                           <td>2</td>
                           <td></td>
                        </tr>

                        <tr>
                           <td>Week-2</td>
                           <td>Gradient Descent,  Chain Rule for Derivatives, Back Propagation, Update Rule, Implementation of Multilayer Perceptron from Scratch that uses back propagation</td>
                           <td>2</td>
                           <td></td>
                        </tr>

                        <tr>
                           <td>Week-3</td>
                           <td>Convolutional Neural Network, Filters, Kernels, Convolutional Layer, Max Pool Layer, Activation Function ReLU, Batch Normalization, Implementation of CNN from Scratch</td>
                           <td>2</td>
                           <td></td>
                        </tr>

                        <tr>
                           <td>Week-4</td>
                           <td>Capacity, Overfitting, Under fitting, Regularization, Weight Decay, Dropout, Batch Normalization, Convolutional AutoEncoder, Semantic Segmentation, Different up-sampling method (Deconvolution, Reverse Maxpool)</td>
                           <td>2</td>
                           <td>Presentation: Semantic Segmentation Presentation<br>1. Segnet<br>2. FCN-8</td>
                        </tr>

                        <tr>
                           <td>Week-5</td>
                           <td>Attention, Where CNN pays attention for classification Concept:<br>Class Activation Map (CAM)</td>
                           <td>2</td>
                           <td>1. GradCAM <br>Learn to Pay Attention</td>
                        </tr>

                        <tr>
                           <td>Week-6</td>
                           <td>Object Detection, Object localization , Region Proposal, Regional Convolutional Neural Network (R-CNN) , Mask R-CNN</td>
                           <td>2</td>
                           <td>1. YOLO <br>2.Fast R-CNN <br> 3.Faster R-CNN</td>
                        </tr>

                        <tr>
                           <td>Week-7</td>
                           <td>Word Embedding, Word2vec, Negative Sampling,  Character Level Embedding, Sentence Level Embedding</td>
                           <td>2</td>
                           <td>1. Attention all you need<br>2. BERT</td>
                        </tr>

                        <tr>
                           <td>Week-8</td>
                           <td>LSTM/GRU for language model, Neural Machine Translation, LST/GRU + Attention, Image Captioning</td>
                           <td>2</td>
                           <td>1. Show, Attend, and Tell</td>
                        </tr>

                        <tr>
                           <td>Week-9</td>
                           <td>Self-Attention, Transformer for Neural Machine Translation</td>
                           <td>2</td>
                           <td>1. Transformer-XL</td>
                        </tr>

                        <tr>
                           <td>Week-10</td>
                           <td>Introduction to Graph Embedding, Node2vec, Graph Convolution Network</td>
                           <td>2</td>
                           <td>1. Representation Learning on Graphs: Method and Application</td>
                        </tr>

                        <tr>
                           <td>Week-11</td>
                           <td>Graph Neural Network (GNN) style Embedding, Graph Attention Network (GAT) style embedding</td>
                           <td>2</td>
                           <td>1. GraphSage</td>
                        </tr>

                        <tr>
                           <td>Week-12</td>
                           <td>Advanced Topics Variational Auto Encoder, Generative Adversarial Network,  Few/Zero Shot Learning</td>
                           <td>2</td>
                           <td></td>
                        </tr> 

                     </tbody>
                  </table>
               </div>
            </section>   





         </div>
      </div>
   </div>
   <div id="footer"></div>

   <!-- Le javascript
         ================================================== -->
   <!-- Placed at the end of the document so the pages load faster -->
   <!-- <script src="js/jquery-1.9.1.min.js"></script> -->
   <script src="js/bootstrap.min.js"></script>
   <script>
      $(document).ready(function () {
         $(document.body).scrollspy({
            target: "#navparent"
         });
      });

   </script>
</body>

</html>
